{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this tutorial, we demonstrate how to use PHATE (Potential of Heat-diffusion for Affinity-based Transition Embedding) to analyze a 31,000 cell 27-day time course of embryoid body (EB) differentiation. We review the following steps:\n",
    "\n",
    "[1. Loading 10X data](#loading)  \n",
    "[2. Preprocessing: Filtering, Normalizing, and Transforming](#preprocessing)  \n",
    "[3. Embedding Data Using PHATE](#embedding)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time course of human embryoid body differentation\n",
    "\n",
    "Low passage H1 hESCs were maintained on Matrigel-coated dishes in DMEM/F12-N2B27 media supplemented with FGF2. For EB formation, cells were treated with Dispase, dissociated into small clumps and plated in non-adherent plates in media supplemented with 20% FBS,\n",
    "45\n",
    "which was prescreened for EB differentiation. Samples were collected during 3-day intervals during a 27 day-long differentiation timecourse. An undifferentiated hESC sample was also included (Figure S7D). Induction of key germ layer markers in these EB cultures was validated by qPCR (data not shown). For single cell analyses, EB cultures were dissociated, FACS sorted to remove doublets and dead cells and processed on a 10x genomics instrument to generate cDNA libraries, which were then sequenced. Small scale sequencing determined that we have successfully collected data on approximately 31,000 cells equally distributed throughout the timecourse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loading'></a>\n",
    "## 1. Loading 10X data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Data from Mendeley Datasets\n",
    "\n",
    "The EB dataset is publically available as `scRNAseq.zip` at Mendelay Datasets at <https://data.mendeley.com/datasets/v6n743h5ng/>. \n",
    "\n",
    "Inside the scRNAseq folder, there are five subdirectories, and in each subdirectory are three files: `barcodes.tsv`, `genes.tsv`, and `matrix.mtx`. For more information about how CellRanger produces these files, check out the [Gene-Barcode Matrices Documentation](https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/output/matrices).\n",
    "\n",
    "Here's the directory structure:\n",
    "```\n",
    "download_path\n",
    "└── scRNAseq\n",
    "    ├── scRNAseq.zip\n",
    "    ├── T0_1A\n",
    "    │   ├── barcodes.tsv\n",
    "    │   ├── genes.tsv\n",
    "    │   └── matrix.mtx\n",
    "    ├── T2_3B\n",
    "    │   ├── barcodes.tsv\n",
    "    │   ├── genes.tsv\n",
    "    │   └── matrix.mtx\n",
    "    ├── T4_5C\n",
    "    │   ├── barcodes.tsv\n",
    "    │   ├── genes.tsv\n",
    "    │   └── matrix.mtx\n",
    "    ├── T6_7D\n",
    "    │   ├── barcodes.tsv\n",
    "    │   ├── genes.tsv\n",
    "    │   └── matrix.mtx\n",
    "    └── T8_9E\n",
    "        ├── barcodes.tsv\n",
    "        ├── genes.tsv\n",
    "        └── matrix.mtx\n",
    "```\n",
    "\n",
    "If you have downloaded the files already, set the `download_path` below to the directory where you saved the files. If not, the following code will download the data for you. Not that the download is 746MB: you must have sufficient disk space for the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "download_path = os.path.expanduser(\"~\")\n",
    "print(download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir(os.path.join(download_path, \"scRNAseq\", \"T0_1A\")):\n",
    "    if not os.path.isdir(download_path):\n",
    "        os.mkdir(download_path)\n",
    "    zip_data = os.path.join(download_path, \"scRNAseq.zip\")\n",
    "    if not os.path.isfile(zip_data):\n",
    "        with urlopen(\"https://data.mendeley.com/datasets/v6n743h5ng\"\n",
    "                     \"/1/files/7489a88f-9ef6-4dff-a8f8-1381d046afe3/scRNAseq.zip?dl=1\") as url:\n",
    "            print(\"Downloading data file...\")\n",
    "            # Open our local file for writing\n",
    "            with open(zip_data, \"wb\") as handle:\n",
    "                handle.write(url.read())\n",
    "    print(\"Unzipping...\")\n",
    "    with zipfile.ZipFile(zip_data, 'r') as handle:\n",
    "        handle.extractall(os.path.expanduser(\"~\"))\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PHATE.io to import data into Pandas DataFrames\n",
    "\n",
    "\n",
    "The PHATE library has a toolkit for loading 10X data called `phate.io`. The function `load_10X` will automatically load these datasets into a Pandas DataFrame. DataFrames are incredibly useful tools for data analysis in Python. To learn more about them, [check out the Pandas Documentation and Tutorials](https://pandas.pydata.org/pandas-docs/stable/).\n",
    "\n",
    "\n",
    "Let's load the data and create a single datamatrix that we can use for preprocessing, visualization, and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import phate\n",
    "\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Use `phate.io.load_10X` to import all three matrices into a DataFrame for each sample (this may take a few minutes and use several GB of memory)\n",
    "\n",
    "Note: By default, `phate.io.load_10X` loads scRNA-seq data using the Pandas SparseDataFrame [(**see Pandas docs**)](https://pandas.pydata.org/pandas-docs/stable/sparse.html). This is so PHATE runs politely on laptops. However, this will be slower than loading on a dense matrix. To load a dense matrix, pass the `sparse=True` argument to `load_10X`. Here we're using dense matrices for the speed benefits. We use `gene_labels = 'both'` so we can see the gene symbols while still retaining the uniqueness offered by gene IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported data matrix with 4649 cells and 33694 genes.\n",
      "Imported data matrix with 7377 cells and 33694 genes.\n",
      "Imported data matrix with 6245 cells and 33694 genes.\n",
      "Imported data matrix with 6563 cells and 33694 genes.\n",
      "Imported data matrix with 6327 cells and 33694 genes.\n"
     ]
    }
   ],
   "source": [
    "sparse=True\n",
    "T1 = phate.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T0_1A\"), sparse=sparse, gene_labels='both')\n",
    "T2 = phate.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T2_3B\"), sparse=sparse, gene_labels='both')\n",
    "T3 = phate.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T4_5C\"), sparse=sparse, gene_labels='both')\n",
    "T4 = phate.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T6_7D\"), sparse=sparse, gene_labels='both')\n",
    "T5 = phate.io.load_10X(os.path.join(download_path, \"scRNAseq\", \"T8_9E\"), sparse=sparse, gene_labels='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a vector representing the time point of each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_labels = np.hstack([(np.ones(T1.shape[0],dtype=int)),\n",
    "                           (np.ones(T2.shape[0],dtype=int) * 2),\n",
    "                           (np.ones(T3.shape[0],dtype=int) * 3),\n",
    "                           (np.ones(T4.shape[0],dtype=int) * 4),\n",
    "                           (np.ones(T5.shape[0],dtype=int) * 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 4. Merge all datasets and remove temporary files to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EBT_counts = pd.concat([T1, T2, T3, T4, T5])\n",
    "\n",
    "EBT_counts.index = pd.Index(EBT_counts.index.values + '#' + sample_labels.astype(int).astype(str)) # Adding sample label to index because of some overlap in cell barcodes\n",
    "\n",
    "del T1, T2, T3, T4, T5 # removes objects from memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='preprocessing'></a>\n",
    "## 2. Preprocessing: Filtering, Normalizing, and Transforming\n",
    "\n",
    "### Filtering\n",
    "\n",
    "We filter the data by: \n",
    "1. Removing dead cells  \n",
    "2. Filtering by library size  \n",
    "3. Removing genes that are expressed in relatively few cells.\n",
    "\n",
    "#### 2.1 Dead cell removal\n",
    "\n",
    "Dead cells are likely to have a higher mitochondrial RNA expression level than live cells. Therefore, we remove suspected dead cells by eliminating cells that have the highest mitochondrial RNA expression levels on average.  \n",
    "\n",
    "First let's look at the distribution of mitochontrial genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mito_genes = [gene_symbol.startswith('MT-') for gene_symbol in EBT_counts.columns] # Get all mitochondrial genes. There are 14, FYI.\n",
    "\n",
    "lib_size =  EBT_counts.sum(axis=1)\n",
    "\n",
    "mito_expression = np.mean(EBT_counts.loc[:,mito_genes].values / lib_size.values[:,None], axis=1)\n",
    "\n",
    "top_pct = np.percentile(mito_expression, 90) # top 10 percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h = plt.hist(mito_expression , bins=100)\n",
    "plt.axvline(top_pct, c='r', label='90th percentile')\n",
    "plt.xlabel('Mean Normalized Mitochondrial Expression', fontsize=16)\n",
    "plt.ylabel('Number of Cells', fontsize=16)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that above the top 90th percentile, there is a steep increase in expression of mitochondrial RNAs. We'll remove these cells from further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EBT_counts    = EBT_counts.iloc[mito_expression < top_pct]\n",
    "sample_labels = sample_labels[mito_expression < top_pct]\n",
    "lib_size      = lib_size[mito_expression < top_pct]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Library size filtering **\n",
    "\n",
    "We filter out cells that have either very large or very small library sizes. For this data set, library size correlates somewhat with sample and so we filter on a per-sample basis. In this case, we eliminate the top and bottom 20% of cells for each sample. Similar results are obtained with less conservative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cells_to_drop = np.zeros(EBT_counts.shape[0],dtype=bool)\n",
    "\n",
    "for i in [1,2,3,4,5]:\n",
    "    cells = sample_labels == i\n",
    "    \n",
    "    min_ls = np.percentile(lib_size[cells], 20)\n",
    "    max_ls = np.percentile(lib_size[cells], 80)\n",
    "    drop_mask = (min_ls >= lib_size) | (lib_size >= max_ls)\n",
    "    \n",
    "    cells_to_drop[cells & drop_mask] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EBT_counts    = EBT_counts.iloc[~cells_to_drop]\n",
    "sample_labels = sample_labels[~cells_to_drop]\n",
    "lib_size      = lib_size[~cells_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Remove rare genes\n",
    "\n",
    "We eliminate genes that are expressed in 10 cells or fewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes_keep=sum(data)>10\n",
    "data=data(:,genes_keep)\n",
    "genes=genes(genes_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genes_keep = np.sum(EBT_counts, axis=0) > 10\n",
    "EBT_counts = EBT_counts.loc[:,genes_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "To correct for differences in library sizes, we divide each cell by its library size and then rescale by the median library size.\n",
    "\n",
    "In python this is performed using the preprocessing method `library_size_normalize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EBT_counts = phate.preprocessing.library_size_normalize(EBT_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "In scRNA-seq analysis, the data is often $\\log$-transformed. This typically requires the addition of some small value to avoid taking $\\log(0)$. We avoid this issue entirely by instead taking the square root transform. The square root function has a similar form as the $\\log$ function with the added benefit of being stable at 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EBT_counts = np.sqrt(EBT_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='embedding'></a>\n",
    "## 3. Embedding Data Using PHATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Instantiating the PHATE estimator\n",
    "\n",
    "The API of PHATE models that of SciKit-Learn. First, you instantiate a PHATE estimator object with the parameters for fitting the PHATE embedding to a given dataset. Next, you use the `fit` and `fit_transform` functions to generate an embedding. For more information, check out [**the PHATE readthedocs page**](http://phate.readthedocs.io/en/latest/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the simplest way to apply PHATE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phate_operator = phate.PHATE(n_components=2, n_jobs=-2)\n",
    "\n",
    "Y_2Dmmds = phate_operator.fit_transform(EBT_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we plot using matplotlib. If you want more help on using Matplotlib, they have [**extensive documentation**](https://matplotlib.org/tutorials/index.html) and [**many Stackoverflow threads**](https://stackoverflow.com/questions/tagged/matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_size_inches(10,8)\n",
    "\n",
    "sc = ax.scatter(Y_2Dmmds[:,0], Y_2Dmmds[:,1], c=sample_labels, s=3)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('PHATE 1', fontsize=15)\n",
    "ax.set_ylabel('PHATE 2', fontsize=15)\n",
    "\n",
    "ax.set_title('')\n",
    "\n",
    "f.colorbar(sc, ticks=[1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are looking for subtle structure and some of the trajectories are sparse, we might want to decrease `k` from the default of 15 and use alpha decay, which creates weak long-range connections. \n",
    "\n",
    "Alpha decay is automatically disabled on large datasets. To override this default, we use the argument `alpha_decya=True` - this increases the memory requirements of PHATE, so it is not advised for extremely large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phate_operator = phate.PHATE(n_components=2, a=10, k=12, alpha_decay=True, n_jobs=-2)\n",
    "\n",
    "Y_2Dmmds = phate_operator.fit_transform(EBT_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1)\n",
    "f.set_size_inches(10,8)\n",
    "\n",
    "sc = ax.scatter(Y_2Dmmds[:,0], Y_2Dmmds[:,1], c=sample_labels, s=3)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('PHATE 1', fontsize=15)\n",
    "ax.set_ylabel('PHATE 2', fontsize=15)\n",
    "\n",
    "ax.set_title('')\n",
    "\n",
    "f.colorbar(sc, ticks=[1,2,3,4,5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
